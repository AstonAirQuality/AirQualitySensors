{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "58e6f625ba2c43b7fc3c95c61d4ef7749e639023949ab2a4f0956b7241794ddb"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# PostGreSQL in Jupyter"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\r\n",
    "import psycopg2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "%store -r sensorIds\r\n",
    "print(sensorIds)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['18699', '18720', '18749']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "#reads in hashmap containing paths to csv files. The keys of these paths are represented as the sensor serial numbers\r\n",
    "%store -r hashmap\r\n",
    "print(hashmap)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'18699': '..\\\\data\\\\flow\\\\task_177_1627319652\\\\sensor_18699\\\\sensor_measures_20210717_20210721_1.csv', '18720': '..\\\\data\\\\flow\\\\task_177_1627319652\\\\sensor_18720\\\\sensor_measures_20210711_20210721_1.csv', '18749': '..\\\\data\\\\flow\\\\task_177_1627319652\\\\sensor_18749\\\\sensor_measures_20210716_20210721_1.csv'}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "#bringing the csv to pandas dataframes\r\n",
    "dfList = []\r\n",
    "for snum in sensorIds:\r\n",
    "    dfList.append(pd.read_csv(hashmap[snum],parse_dates=True, index_col=\"timestamp\"))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "#put the dataframes into a dictionary with the sensor id as the key\r\n",
    "dataframes = {k:v for k,v in zip(sensorIds,dfList)}\r\n",
    "dataframes[sensorIds[0]].head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                           date  NO2 (ppb)  NO2 (Plume AQI)  VOC (ppb)  \\\n",
       "timestamp                                                                \n",
       "1626501264  2021-07-17 05:54:24          0                0         63   \n",
       "1626501324  2021-07-17 05:55:24          2                2         56   \n",
       "1626501384  2021-07-17 05:56:24          5                4         51   \n",
       "1626501444  2021-07-17 05:57:24          0                0         47   \n",
       "1626501504  2021-07-17 05:58:24          2                2         45   \n",
       "\n",
       "            VOC (Plume AQI)  pm 1 (ug/m3)  pm 1 (Plume AQI)  pm 10 (ug/m3)  \\\n",
       "timestamp                                                                    \n",
       "1626501264                5             6                15             82   \n",
       "1626501324                4             3                 8              5   \n",
       "1626501384                4             3                 8              5   \n",
       "1626501444                4             3                 8              5   \n",
       "1626501504                4             4                11             43   \n",
       "\n",
       "            pm 10 (Plume AQI)  pm25 (ug/m3)  pm 25 (Plume AQI)  \n",
       "timestamp                                                       \n",
       "1626501264                102            12                 23  \n",
       "1626501324                  5             4                  9  \n",
       "1626501384                  5             4                  8  \n",
       "1626501444                  5             4                  8  \n",
       "1626501504                 43             6                 12  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>NO2 (ppb)</th>\n",
       "      <th>NO2 (Plume AQI)</th>\n",
       "      <th>VOC (ppb)</th>\n",
       "      <th>VOC (Plume AQI)</th>\n",
       "      <th>pm 1 (ug/m3)</th>\n",
       "      <th>pm 1 (Plume AQI)</th>\n",
       "      <th>pm 10 (ug/m3)</th>\n",
       "      <th>pm 10 (Plume AQI)</th>\n",
       "      <th>pm25 (ug/m3)</th>\n",
       "      <th>pm 25 (Plume AQI)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1626501264</th>\n",
       "      <td>2021-07-17 05:54:24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>82</td>\n",
       "      <td>102</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1626501324</th>\n",
       "      <td>2021-07-17 05:55:24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>56</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1626501384</th>\n",
       "      <td>2021-07-17 05:56:24</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>51</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1626501444</th>\n",
       "      <td>2021-07-17 05:57:24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1626501504</th>\n",
       "      <td>2021-07-17 05:58:24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "#Connecting to an existing database\r\n",
    "con = psycopg2.connect(\r\n",
    "    host=\"localhost\",\r\n",
    "    database=\"sdb_airQuality\",\r\n",
    "    user=\"Riyad\", \r\n",
    "    password=\"123\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "#Opening a cursor to execute database operations\r\n",
    "cur = con.cursor()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Measurement data\n",
    "## Reading the database \n",
    "\n",
    "We have to check if there is already an existing measurement table before we add the new data. <br>\n",
    "if there is already a table with the same name, then we need to subset the data from the dataframe removing all the data up to the last entry from the database. We can then upload the new dataframe as a seperate table and execute an SQL union command to join the tables together. <br>\n",
    "else, the table does not exist already and therefore we can just upload the entire dataframe as a new table."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "from psycopg2 import sql\r\n",
    "\r\n",
    "tableExist = True\r\n",
    "\r\n",
    "for snum in sensorIds: \r\n",
    "    try: \r\n",
    "        cur.execute(sql.SQL(\"SELECT * FROM {}\").format(sql.Identifier(snum)))\r\n",
    "    except psycopg2.Error as e:\r\n",
    "        if e.pgcode == \"25P02\":\r\n",
    "            print(\"No table exists yet, importing as a new table\")\r\n",
    "            tableExist = False\r\n",
    "        else:\r\n",
    "            print(\"An unexpected error has occured, Error code: \" + e.pgcode)\r\n",
    "\r\n",
    "#cur.execute(sql.SQL(\"SELECT * FROM {} WHERE id = %s\").format(sql.Identifier(Username)),[cur.rowcount-1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "If the table already exists we simply add _clone to the new table we will add"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "#if the table exists then we should get the rows after the last entry which exists in the database.\r\n",
    "if tableExist == True:\r\n",
    "    print(\"This table already exists, Creating clone table . . .\")\r\n",
    "    #df = df[df.id > cur.rowcount - 1]\r\n",
    "    #print(smoothdf.head(1))\r\n",
    "    #Username += \"_clone\"\r\n",
    "    \r\n",
    "else:\r\n",
    "    print(\"Continue from next code block\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "This table already exists, Creating clone table . . .\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-106cc3c1a2fe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtableExist\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"This table already exists, Creating clone table . . .\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mcur\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrowcount\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;31m#print(smoothdf.head(1))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mUsername\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m\"_clone\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "print(\"dataframe is ready for upload\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dataframe is ready for upload\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# drop date column adn add sensor id column (foreign key)\r\n",
    "for key in dataframes:\r\n",
    "    print(key)\r\n",
    "    df = dataframes[key]\r\n",
    "    df.drop(\"date\", axis=1, inplace=True)\r\n",
    "    df['sensor_id'] = key\r\n",
    "    dataframes[key] = df    #assign new dataframe to coressponding key"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "18699\n",
      "18720\n",
      "18749\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "cur.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Writing records from a DataFrame to a SQL database\n",
    "Using create_engine() from sqlaclhemy we can generate and execute an SQL query to store the entire dataframe into a table "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "from sqlalchemy import create_engine\r\n",
    "from sqlalchemy import exc"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "#engine = create_engine('postgresql://username:password@localhost:5432/mydatabase')\r\n",
    "\r\n",
    "for key in dataframes: \r\n",
    "    try: \r\n",
    "        tableName = key\r\n",
    "        engine = create_engine('postgresql+psycopg2://Riyad:123@localhost/sdb_airQuality')\r\n",
    "        dataframes[key].to_sql(tableName, engine)\r\n",
    "    except exc.SQLAlchemyError as e:\r\n",
    "        print(e)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "con.commit()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "con.close()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ]
}